{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJJ2iO8794ShW8RK1NapFm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gusujio/neural_networks_start/blob/master/Linear_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17oh4umABWzQ",
        "colab_type": "text"
      },
      "source": [
        "Полносвязный слой может быть представлен как матричное умножение матрицы входов (X) и матрицы весов нейронов слоя (W), плюс вектор bias'ов слоя (b). \n",
        "\n",
        "В документации к классу torch.nn.Linear (полносвязному слою) написано следующее: Applies a linear transformation to the incoming data: y = xA^T + b. А здесь – это то, как PyTorch хранит веса слоя. Но чтобы эта матрица совпала с W из предыдущего урока, нужно её сперва транспонировать.\n",
        "\n",
        "# Давайте реализуем функциональность torch.nn.Linear и сверим с оригиналом!\n",
        "\n",
        "Пусть у нас будет 1 объект x на входе с двумя компонентами. Его мы передадим в полносвязный слой с 3-мя нейронами и получим, соотсветственно, 3 выхода. После напишем эту же функциональность с помощью матричного умножения. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeshAiRxBJ7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d4b771f-c25d-4e8c-af94-de09e5bda2cb"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Сперва создадим тензор x:\n",
        "x = torch.tensor([[10., 20.]])\n",
        "\n",
        "# Оригинальный полносвязный слой с 2-мя входами и 3-мя нейронами (выходами):\n",
        "fc = torch.nn.Linear(2, 3)\n",
        "\n",
        "# Веса fc-слоя хранятся в fc.weight, а bias'ы соответственно в fc.bias\n",
        "# fc.weight и fc.bias по умолчанию инициализируются случайными числами\n",
        "\n",
        "# Давайте проставим свои значения в веса и bias'ы:\n",
        "w = torch.tensor([[11., 12.], [21., 22.], [31., 32]])\n",
        "fc.weight.data = w\n",
        "\n",
        "b = torch.tensor([[31., 32., 33.]])\n",
        "fc.bias.data = b\n",
        "\n",
        "# Получим выход fc-слоя:\n",
        "fc_out = fc(x)\n",
        "\n",
        "# Попробуем теперь получить аналогичные выходы с помощью матричного перемножения:\n",
        "#fc_out_alternative =  x * w.t() + b\n",
        "fc_out_alternative =  torch.mm(x, w.t()) + b\n",
        "# Проверка осуществляется автоматически вызовом функции\n",
        "print(fc_out == fc_out_alternative)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[True, True, True]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp3HpL24Bslo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "56ff0433-a331-4309-ee5f-72472cc0e392"
      },
      "source": [
        "w.t(), x, b"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[11., 21., 31.],\n",
              "         [12., 22., 32.]]), tensor([[10., 20.]]), tensor([[31., 32., 33.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH-vHkn8B7wW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f31759b6-159c-47df-a6d8-2b7629e71a83"
      },
      "source": [
        "torch.mm(x, w.t()) + b"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[381., 682., 983.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9H5LGgbCJbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}